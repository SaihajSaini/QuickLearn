import { Buffer } from "node:buffer";
import { createHash } from "node:crypto";
import dns from "node:dns";
import http from "node:http";
import https from "node:https";
import path, { basename, dirname, isAbsolute, join, resolve } from "node:path";
import axios from "axios";
import fs, { ensureDirSync, pathExists } from "fs-extra";
import sanitize from "sanitize-filename";
import slugify from "slugify";
import { $URL, hasProtocol, isRelative, joinURL, normalizeURL, withBase, withLeadingSlash, withQuery, withTrailingSlash, withoutLeadingSlash, withoutTrailingSlash } from "ufo";
import fs$1, { existsSync, readFileSync } from "node:fs";
import { loadConfig } from "c12";
import { box, colorize } from "consola/utils";
import { createDefu, defu } from "defu";
import { createHooks } from "hookable";
import { createCommonJS, resolve as resolve$1, resolvePath } from "mlly";
import objectHash from "object-hash";
import { $fetch } from "ofetch";
import { createContext } from "unctx";
import { get, groupBy, map, pick, sampleSize, sortBy, sumBy, uniqBy } from "lodash-es";
import os, { homedir } from "node:os";
import { Cluster } from "puppeteer-cluster";
import { createConsola } from "consola";
import { normalize, relative, resolve as resolve$2 } from "pathe";
import { createUnrouted, get as get$1, post, prefix, redirect, setStatusCode, useParams, useQuery } from "@unrouted/core";
import { presetApi } from "@unrouted/preset-api";
import { presetNode, serve } from "@unrouted/preset-node";
import launch from "launch-editor";
import { WebSocketServer } from "ws";
import { parse } from "regexparam";
import Sitemapper from "sitemapper";
import { load } from "cheerio";
import { createRouter, toRouteMatcher } from "radix3";
import { computeMedianRun } from "lighthouse/core/lib/median-run.js";
import * as p from "@clack/prompts";
import { computeExecutablePath, detectBrowserPlatform, install } from "@puppeteer/browsers";
import { Launcher } from "chrome-launcher";
import puppeteer, { launch as launch$1 } from "puppeteer-core";
import { PUPPETEER_REVISIONS } from "puppeteer-core/lib/cjs/puppeteer/revisions.js";
import wrapAnsi from "wrap-ansi";

//#region package.json
var version = "0.17.2";

//#endregion
//#region src/data/scanMeta.ts
function createScanMeta() {
	const { worker } = useUnlighthouse();
	const data = worker.reports().filter((r) => r.tasks.inspectHtmlTask === "completed");
	const reportsWithScore = data.filter((r) => r.report?.score);
	const score = reportsWithScore.map((r) => r.report.score).reduce((s, a) => s + a, 0) / reportsWithScore.length || 0;
	return {
		favicon: data?.[0]?.seo?.favicon,
		monitor: worker.monitor(),
		routes: data.length || 0,
		score
	};
}

//#endregion
//#region src/build.ts
/**
* Copies the file contents of the @unlighthouse/client package and does transformation based on the provided configuration.
*
* The main transformation is injecting the unlighthouse configuration into the head of the document, making it accessible
* to the client.
*
* An additional transforming is needed to modify the vite base URL which is a bit more involved.
*/
async function generateClient(options = {}, unlighthouse) {
	const logger = useLogger();
	if (!unlighthouse) unlighthouse = useUnlighthouse();
	const { runtimeSettings, resolvedConfig, worker } = unlighthouse;
	let prefix$1 = withTrailingSlash(withLeadingSlash(resolvedConfig.routerPrefix));
	if (prefix$1 === "/") prefix$1 = "";
	const clientPathFolder = dirname(runtimeSettings.resolvedClientPath);
	await fs.copy(clientPathFolder, runtimeSettings.generatedClientPath);
	const inlineScript = `window.__unlighthouse_static = ${!!options.static}`;
	let indexHTML = await fs.readFile(runtimeSettings.resolvedClientPath, "utf-8");
	indexHTML = indexHTML.replace(/<script data-unlighthouse-inline>[\s\S]*?<\/script>/g, `<script data-unlighthouse-inline>
  ${inlineScript}
  // boilerplate options to run the client by itself
  </script>`).replace(/(href|src)="\/assets\/(.*?)"/g, `$1="${prefix$1}assets/$2"`);
	await fs.writeFile(resolve(runtimeSettings.generatedClientPath, "index.html"), indexHTML, "utf-8");
	const staticData = {
		reports: [],
		scanMeta: createScanMeta(),
		options: pick({
			...runtimeSettings,
			...resolvedConfig
		}, [
			"client",
			"site",
			"websocketUrl",
			"lighthouseOptions",
			"scanner",
			"routerPrefix",
			"websocketUrl",
			"apiUrl"
		])
	};
	staticData.options.lighthouseOptions = { onlyCategories: resolvedConfig.lighthouseOptions.onlyCategories };
	if (options.static) staticData.reports = worker.reports().map((r) => {
		return {
			...r,
			artifactPath: ""
		};
	});
	await fs.writeFile(join(runtimeSettings.generatedClientPath, "assets", "payload.js"), `window.__unlighthouse_payload = ${JSON.stringify(staticData)}`, { encoding: "utf-8" });
	const globby = await import("globby");
	const clientAssetsPath = join(dirname(runtimeSettings.resolvedClientPath), "assets");
	logger.debug(`Looking for index.*.js files in: ${clientAssetsPath}`);
	const indexFiles = await globby.globby(["index*.js", "index-*.js"], { cwd: clientAssetsPath });
	logger.debug(`Found index files:`, indexFiles);
	const indexFile = indexFiles?.[0];
	if (indexFile) {
		const indexPath = join(clientAssetsPath, indexFile);
		const outputPath = join(runtimeSettings.generatedClientPath, "assets", indexFile);
		logger.debug(`Processing index file: ${indexPath} -> ${outputPath}`);
		let indexJS = await fs.readFile(indexPath, "utf-8");
		indexJS = indexJS.replace("const base = \"/\";", `const base = window.location.pathname;`).replace("createWebHistory(\"/\")", `createWebHistory(window.location.pathname)`);
		await fs.writeFile(outputPath, indexJS, "utf-8");
	} else {
		logger.warn(`Failed to find index.[hash].js file from wd ${clientAssetsPath}.`);
		logger.debug(`Searched patterns: ['index*.js', 'index-*.js']`);
	}
}

//#endregion
//#region src/constants.ts
const AppName = "Unlighthouse";
const ClientPkg = "@unlighthouse/client";
const DefaultColumns = {
	"overview": [{
		label: "Screenshot Timeline",
		key: "report.audits.screenshot-thumbnails",
		cols: 6
	}],
	"performance": [
		{
			cols: 1,
			label: "FCP",
			tooltip: "First Contentful Paint marks the time at which the first text or image is painted. [Learn more about the First Contentful Paint metric](https://developer.chrome.com/docs/lighthouse/performance/first-contentful-paint/).",
			key: "report.audits.first-contentful-paint",
			sortKey: "numericValue"
		},
		{
			cols: 2,
			label: "LCP",
			tooltip: "Largest Contentful Paint marks the time at which the largest text or image is painted. [Learn more](https://web.dev/lighthouse-largest-contentful-paint/)",
			key: "report.audits.largest-contentful-paint",
			sortKey: "numericValue"
		},
		{
			cols: 2,
			label: "CLS",
			tooltip: "Cumulative Layout Shift measures the movement of visible elements within the viewport.",
			sortKey: "numericValue",
			key: "report.audits.cumulative-layout-shift"
		},
		{
			cols: 1,
			label: "FID",
			warning: true,
			tooltip: "Warning: This is deprecated in favour if INP which is not yet supported by Unlighthouse. The maximum potential First Input Delay that your users could experience is the duration of the longest task. [Learn more](https://web.dev/lighthouse-max-potential-fid/).",
			sortKey: "numericValue",
			key: "report.audits.max-potential-fid"
		},
		{
			cols: 1,
			label: "TBT",
			tooltip: "Sum of all time periods between FCP and Time to Interactive, when task length exceeded 50ms, expressed in milliseconds. [Learn more](https://web.dev/lighthouse-total-blocking-time/).",
			sortKey: "numericValue",
			key: "report.audits.total-blocking-time"
		},
		{
			cols: 1,
			label: "SI",
			sortKey: "numericValue",
			tooltip: "The speed index is a page load performance metric that shows you how quickly the contents of a page are visibly populated. [Learn more](https://web.dev/speed-index/).",
			key: "report.audits.speed-index"
		}
	],
	"accessibility": [
		{
			cols: 3,
			label: "Color Contrast",
			tooltip: "Background and foreground colors do not have a sufficient contrast ratio.",
			sortKey: "length:details.items",
			key: "report.audits.color-contrast"
		},
		{
			cols: 1,
			label: "Headings",
			tooltip: "Heading elements appear in a sequentially-descending order",
			sortKey: "length:details.items",
			key: "report.audits.heading-order"
		},
		{
			cols: 1,
			label: "ARIA",
			tooltip: "An aggregate of all ARIA audits.",
			sortKey: "displayValue",
			sortable: true,
			key: "report.computed.ariaIssues"
		},
		{
			cols: 1,
			label: "Labels",
			tooltip: "Form elements have associated labels",
			sortKey: "length:details.items",
			key: "report.audits.label"
		},
		{
			cols: 1,
			label: "Image Alts",
			tooltip: "Image elements have [alt] attributes",
			sortKey: "length:details.items",
			key: "report.audits.image-alt"
		},
		{
			cols: 1,
			label: "Link Names",
			tooltip: "Links do not have a discernible name",
			sortKey: "length:details.items",
			key: "report.audits.link-name"
		}
	],
	"best-practices": [
		{
			cols: 2,
			label: "Errors",
			tooltip: "No browser errors logged to the console",
			sortKey: "length:details.items",
			key: "report.audits.errors-in-console"
		},
		{
			cols: 2,
			label: "Inspector Issues",
			tooltip: "No issues in the `Issues` panel in Chrome Devtools",
			sortKey: "length:details.items",
			key: "report.audits.inspector-issues"
		},
		{
			cols: 2,
			label: "Images Responsive",
			tooltip: "Serves images with appropriate resolution",
			sortKey: "length:details.items",
			key: "report.audits.image-size-responsive"
		},
		{
			cols: 2,
			label: "Image Aspect Ratio",
			tooltip: "Displays images with correct aspect ratio",
			sortKey: "length:details.items",
			key: "report.audits.image-aspect-ratio"
		}
	],
	"seo": [
		{
			cols: 1,
			label: "Indexable",
			tooltip: "Page isnâ€™t blocked from indexing",
			key: "report.audits.is-crawlable"
		},
		{
			cols: 1,
			label: "Internal link",
			sortable: true,
			key: "seo.internalLinks"
		},
		{
			cols: 1,
			label: "External link",
			sortable: true,
			key: "seo.externalLinks"
		},
		{
			cols: 2,
			label: "Description",
			key: "seo.description"
		},
		{
			cols: 2,
			label: "Share Image",
			key: "seo.og.image"
		}
	]
};
const defaultConfig = {
	routerPrefix: "/",
	apiPrefix: "/api",
	cache: true,
	client: {
		groupRoutesKey: "route.definition.name",
		columns: DefaultColumns
	},
	scanner: {
		customSampling: {},
		ignoreI18nPages: true,
		maxRoutes: 200,
		skipJavascript: true,
		samples: 1,
		throttle: true,
		crawler: true,
		dynamicSampling: 8,
		sitemap: true,
		robotsTxt: true,
		device: "mobile"
	},
	server: {
		port: 5678,
		showURL: false,
		open: true
	},
	discovery: {
		supportedExtensions: ["vue", "md"],
		pagesDir: "pages"
	},
	root: process.cwd(),
	outputPath: ".unlighthouse",
	debug: false,
	puppeteerOptions: {},
	puppeteerClusterOptions: {
		monitor: true,
		workerCreationDelay: 500,
		retryLimit: 3,
		timeout: 5 * 60 * 1e3,
		maxConcurrency: Math.max(Math.floor(os.cpus().length / 2), 1),
		skipDuplicateUrls: false,
		retryDelay: 2e3,
		concurrency: Cluster.CONCURRENCY_BROWSER
	},
	lighthouseOptions: { onlyCategories: [
		"performance",
		"accessibility",
		"best-practices",
		"seo"
	] }
};

//#endregion
//#region src/logger.ts
const loggerCtx = createContext();
function createLogger(debug = false) {
	const logger = createConsola().withTag(AppName);
	if (debug) logger.level = 4;
	loggerCtx.set(logger);
	return logger;
}
/**
* Gets the instantiated logger instance using the shared context, persists the application logging configuration.
*/
const useLogger = () => {
	let logger = loggerCtx.use();
	if (!logger) logger = createLogger();
	return logger;
};

//#endregion
//#region src/discovery/robotsTxt.ts
/**
* Fetches the robots.txt file.
* @param site
*/
async function fetchRobotsTxt(site) {
	site = new $URL(site).origin;
	const unlighthouse = useUnlighthouse();
	const logger = useLogger();
	logger.debug(`Scanning ${site}/robots.txt`);
	const robotsTxt = await fetchUrlRaw(`${site}/robots.txt`, unlighthouse.resolvedConfig);
	if (!robotsTxt.valid || !robotsTxt.response) {
		logger.warn("You seem to be missing a robots.txt.");
		return false;
	}
	logger.debug("Found robots.txt");
	return robotsTxt.response.data;
}
function matches(pattern, path$1) {
	const pathLength = path$1.length;
	const patternLength = pattern.length;
	const matchingLengths = Array.from({ length: pathLength + 1 }).fill(0);
	let numMatchingLengths = 1;
	let p$1 = 0;
	while (p$1 < patternLength) {
		if (pattern[p$1] === "$" && p$1 + 1 === patternLength) return matchingLengths[numMatchingLengths - 1] === pathLength;
		if (pattern[p$1] === "*") {
			numMatchingLengths = pathLength - matchingLengths[0] + 1;
			for (let i = 1; i < numMatchingLengths; i++) matchingLengths[i] = matchingLengths[i - 1] + 1;
		} else {
			let numMatches = 0;
			for (let i = 0; i < numMatchingLengths; i++) {
				const matchLength = matchingLengths[i];
				if (matchLength < pathLength && path$1[matchLength] === pattern[p$1]) matchingLengths[numMatches++] = matchLength + 1;
			}
			if (numMatches === 0) return false;
			numMatchingLengths = numMatches;
		}
		p$1++;
	}
	return true;
}
function matchPathToRule(path$1, _rules) {
	let matchedRule = null;
	const rules = _rules.filter(Boolean);
	const rulesLength = rules.length;
	let i = 0;
	while (i < rulesLength) {
		const rule = rules[i];
		if (!matches(rule.pattern, path$1)) {
			i++;
			continue;
		}
		if (!matchedRule || rule.pattern.length > matchedRule.pattern.length) matchedRule = rule;
		else if (rule.pattern.length === matchedRule.pattern.length && rule.allow && !matchedRule.allow) matchedRule = rule;
		i++;
	}
	return matchedRule || {
		pattern: "",
		allow: true
	};
}
function mergeRobotsTxtConfig(config, { groups, sitemaps }) {
	config.scanner._robotsTxtRules = groups.filter((group) => {
		return group.userAgent.includes("*") || group.userAgent.includes(String(config.lighthouseOptions?.emulatedUserAgent));
	}).flatMap((group) => group._rules);
	if (config.scanner.sitemap !== false && sitemaps.length) {
		if (!Array.isArray(config.scanner.sitemap) || !config.scanner.sitemap.length) config.scanner.sitemap = [...new Set([...Array.isArray(config.scanner.sitemap) ? config.scanner.sitemap : [], ...sitemaps])];
	}
}

//#endregion
//#region src/util/createRoutes.ts
const DYNAMIC_ROUTE_REGEX = /^\/[:*]/;
function getRoutePathExtension(key) {
	if (key === "_") return "*";
	if (key.startsWith("_")) return `:${key.substring(1)}`;
	return key;
}
function sortRoutes(routes) {
	routes.sort((a, b) => {
		if (!a.path.length) return -1;
		if (!b.path.length) return 1;
		if (a.path === "/") return DYNAMIC_ROUTE_REGEX.test(b.path) ? -1 : 1;
		if (b.path === "/") return DYNAMIC_ROUTE_REGEX.test(a.path) ? 1 : -1;
		let i;
		let res = 0;
		let y = 0;
		let z = 0;
		const _a = a.path.split("/");
		const _b = b.path.split("/");
		for (i = 0; i < _a.length; i++) {
			if (res !== 0) break;
			y = _a[i] === "*" ? 2 : _a[i].includes(":") ? 1 : 0;
			z = _b[i] === "*" ? 2 : _b[i].includes(":") ? 1 : 0;
			res = y - z;
			if (i === _b.length - 1 && res === 0) res = _a[i] === "*" ? -1 : _a.length === _b.length ? a.path.localeCompare(b.path) : _a.length - _b.length;
		}
		if (res === 0) res = _a[i - 1] === "*" && _b[i] ? 1 : _a.length === _b.length ? a.path.localeCompare(b.path) : _a.length - _b.length;
		return res;
	});
	routes.forEach((route) => {
		if (route.children) sortRoutes(route.children);
	});
	return routes;
}
function createRoutes(options) {
	const { files, srcDir, pagesDir = "", routeNameSplitter = "-", supportedExtensions = ["vue", "js"], trailingSlash } = options;
	const routes = [];
	files.forEach((file) => {
		const keys = file.replace(new RegExp(`^${pagesDir}`), "").replace(new RegExp(`\\.(${supportedExtensions.join("|")})$`), "").replace(/\/{2,}/g, "/").split("/").slice(1);
		const route = {
			name: "",
			path: "",
			component: resolve$2(srcDir, file)
		};
		let parent = routes;
		keys.forEach((key, i) => {
			const sanitizedKey = key.startsWith("_") ? key.substr(1) : key;
			route.name = route.name ? route.name + routeNameSplitter + sanitizedKey : sanitizedKey;
			route.name += key === "_" ? "all" : "";
			route.chunkName = file.replace(new RegExp(`\\.(${supportedExtensions.join("|")})$`), "");
			const child = parent.find((parentRoute) => parentRoute.name === route.name);
			if (child) {
				child.children = child.children || [];
				parent = child.children;
				route.path = "";
			} else if (key === "index" && i + 1 === keys.length) route.path += i > 0 ? "" : "/";
			else {
				route.path += `/${normalizeURL(getRoutePathExtension(key))}`;
				if (key.startsWith("_") && key.length > 1) route.path += "?";
			}
		});
		if (trailingSlash !== void 0) {
			route.pathToRegexpOptions = {
				...route.pathToRegexpOptions,
				strict: true
			};
			if (trailingSlash && !route.path.endsWith("*")) route.path = withTrailingSlash(route.path);
			else route.path = withoutTrailingSlash(route.path);
		}
		parent.push(route);
	});
	sortRoutes(routes);
	return cleanChildrenRoutes(routes, false, routeNameSplitter, trailingSlash);
}
function cleanChildrenRoutes(routes, isChild = false, routeNameSplitter = "-", trailingSlash, parentRouteName = "") {
	const regExpIndex = new RegExp(`${routeNameSplitter}index$`);
	const regExpParentRouteName = new RegExp(`^${parentRouteName}${routeNameSplitter}`);
	const routesIndex = [];
	routes.forEach((route) => {
		if (regExpIndex.test(route.name) || route.name === "index") {
			const res = route.name.replace(regExpParentRouteName, "").split(routeNameSplitter);
			routesIndex.push(res);
		}
	});
	routes.forEach((route) => {
		route.path = isChild ? route.path.replace("/", "") : route.path;
		if (route.path.includes("?")) {
			if (route.name.endsWith(`${routeNameSplitter}index`)) route.path = route.path.replace(/\?\/?$/, trailingSlash ? "/" : "");
			const names = route.name.replace(regExpParentRouteName, "").split(routeNameSplitter);
			const paths = route.path.split("/");
			if (!isChild) paths.shift();
			routesIndex.forEach((r) => {
				const i = r.indexOf("index");
				if (i < paths.length) for (let a = 0; a <= i; a++) {
					if (a === i) paths[a] = paths[a].replace("?", "");
					if (a < i && names[a] !== r[a]) break;
				}
			});
			route.path = (isChild ? "" : "/") + paths.join("/");
		}
		route.name = route.name.replace(regExpIndex, "");
		if (route.children) {
			const defaultChildRoute = route.children.find((child) => child.path === "/" || child.path === "");
			const routeName = route.name;
			if (defaultChildRoute) {
				route.children.forEach((child) => {
					if (child.path !== defaultChildRoute.path) {
						const parts = child.path.split("/");
						parts[1] = parts[1].endsWith("?") ? parts[1].substr(0, parts[1].length - 1) : parts[1];
						child.path = parts.join("/");
					}
				});
				delete route.name;
			}
			route.children = cleanChildrenRoutes(route.children, true, routeNameSplitter, trailingSlash, routeName);
		}
	});
	return routes;
}

//#endregion
//#region src/discovery/routeDefinitions.ts
/**
* Using the configuration discovery details will try and resolve the route definitions using the file system.
*/
async function discoverRouteDefinitions() {
	const { resolvedConfig } = useUnlighthouse();
	if (!resolvedConfig.discovery) return [];
	const logger = useLogger();
	const { supportedExtensions, pagesDir } = resolvedConfig.discovery;
	const dir = pagesDir === "" ? resolvedConfig.root.replace(`${resolvedConfig.root}/`, "") : pagesDir;
	const resolveFiles = async (dir$1) => {
		const { globby } = await import("globby");
		const extensions = supportedExtensions.length > 1 ? `{${supportedExtensions.join(",")}}` : supportedExtensions[0];
		return await globby([
			join(dir$1, "**", `*.${extensions}`),
			"!**/README.md",
			"!**/node_modules"
		], {
			cwd: resolvedConfig.root,
			deep: 5,
			gitignore: true
		});
	};
	const files = {};
	const ext = new RegExp(`\\.(${supportedExtensions.join("|")})$`);
	const resolvedPages = await resolveFiles(dir);
	for (const page of resolvedPages) {
		const key = page.replace(ext, "");
		if (/\.vue$/.test(page) || !files[key]) files[key] = page.replace(/(['"])/g, "\\$1");
	}
	logger.debug(`Discovered \`${resolvedPages.length}\` page files from  \`${join(resolvedConfig.root, dir)}\`. Mapping to route definitions.`);
	if (resolvedPages.length) logger.debug(resolvedPages);
	return createRoutes({
		files: Object.values(files),
		srcDir: resolvedConfig.root,
		pagesDir: dir,
		routeNameSplitter: "-",
		supportedExtensions,
		trailingSlash: false
	}).map((route) => {
		const pathNodes = route.path.split("/");
		route.path = pathNodes.map((n) => {
			if (n.startsWith("[") && n.endsWith("]")) {
				const strippedNode = n.replace("[", "").replace("]", "").replace("...", "");
				return `:${strippedNode}`;
			}
			return n;
		}).join("/");
		return route;
	});
}

//#endregion
//#region src/router/api.ts
/**
* The API layer of unlighthouse.
*
* Internally, this uses unrouted which provides an elegant and batteries-packed solution.
*/
async function createApi(h3) {
	const logger = useLogger();
	const { ws, resolvedConfig, runtimeSettings, hooks } = useUnlighthouse();
	const useReport = () => {
		const { worker } = useUnlighthouse();
		const { id } = useParams();
		return worker.findReport(id);
	};
	const { app, setup } = await createUnrouted({
		name: "unlighthouse-api",
		debug: resolvedConfig.debug,
		prefix: resolvedConfig.routerPrefix,
		app: h3,
		hooks: { "serve:before-route": () => {
			return hooks.callHook("visited-client");
		} },
		presets: [presetApi(), presetNode({ generateTypes: false })]
	});
	await setup(() => {
		redirect("/__lighthouse/", resolvedConfig.routerPrefix);
		prefix("/api", () => {
			prefix("/reports", () => {
				post("/rescan", () => {
					const { worker } = useUnlighthouse();
					const reports = [...worker.routeReports.values()];
					logger.info(`Doing site rescan, clearing ${reports.length} reports.`);
					worker.routeReports.clear();
					reports.forEach((route) => {
						const dir = route.artifactPath;
						if (fs.existsSync(dir)) fs.rmSync(dir, { recursive: true });
					});
					worker.queueRoutes(reports.map((report) => report.route));
					return true;
				});
				post("/:id/rescan", () => {
					const report = useReport();
					const { worker } = useUnlighthouse();
					if (report) worker.requeueReport(report);
				});
			});
			get$1("__launch", () => {
				const { file } = useQuery();
				if (!file) {
					setStatusCode(400);
					return false;
				}
				const path$1 = file.replace(resolvedConfig.root, "");
				const resolved = join(resolvedConfig.root, path$1);
				logger.info(`Launching file in editor: \`${path$1}\``);
				launch(resolved);
			});
			get$1("ws", (event) => ws.serve(event.req));
			get$1("reports", () => {
				const { worker } = useUnlighthouse();
				return worker.reports().filter((r) => r.tasks.inspectHtmlTask === "completed");
			});
			get$1("scan-meta", () => createScanMeta());
		});
		serve("/", runtimeSettings.generatedClientPath);
	});
	return app;
}

//#endregion
//#region src/router/broadcasting.ts
/**
* When certain hooks are triggered we need to broadcast data via the web socket.
*/
function createBroadcastingEvents() {
	const { hooks, ws } = useUnlighthouse();
	if (!ws) return;
	hooks.hook("task-started", (path$1, response) => {
		if (response.tasks.inspectHtmlTask === "completed") ws.broadcast({ response });
	});
	hooks.hook("task-complete", (path$1, response) => {
		if (response.tasks.inspectHtmlTask === "completed") ws.broadcast({ response });
	});
	hooks.hook("task-added", (path$1, response) => {
		if (response.tasks.inspectHtmlTask === "completed") ws.broadcast({ response });
	});
}
var WS = class {
	wss;
	constructor() {
		this.wss = new WebSocketServer({ noServer: true });
	}
	serve(req) {
		this.handleUpgrade(req, req.socket);
	}
	handleUpgrade(request, socket) {
		return this.wss.handleUpgrade(request, socket, Buffer.alloc(0), (client) => {
			this.wss.emit("connection", client, request);
		});
	}
	/**
	* Publish event and data to all connected clients
	* @param {object} data
	*/
	broadcast(data) {
		const jsonData = JSON.stringify(data);
		for (const client of this.wss.clients) try {
			client.send(jsonData);
		} catch {}
	}
};

//#endregion
//#region src/router/mockRouter.ts
/**
* The default mock router using regexparam as the matcher
*
* Used by nuxt and the default route definition discoverer.
*
* @param routeDefinitions
*/
const createMockRouter = (routeDefinitions) => {
	const logger = useLogger();
	const patterns = routeDefinitions.map((r) => {
		try {
			return {
				routeDefinition: r,
				matcher: parse(r.path)
			};
		} catch (e) {
			logger.debug("Failed to parse path", r.path, e);
		}
		return false;
	}).filter((r) => r !== false);
	return { match(path$1) {
		const matched = patterns.filter((p$1) => p$1 && p$1.matcher.pattern.test(path$1));
		if (matched.length > 0 && matched[0]) return matched[0].routeDefinition;
		return false;
	} };
};

//#endregion
//#region src/router/util.ts
function isScanOrigin(url) {
	if (isRelative(url) || url.startsWith("/") && !url.startsWith("//")) return true;
	const { runtimeSettings } = useUnlighthouse();
	const $url = new URL(url);
	if ($url.hostname === runtimeSettings.siteUrl.hostname) return true;
	return $url.hostname.endsWith(`.${runtimeSettings.siteUrl.hostname}`);
}
/**
* Due to working with routes from all different frameworks or no framework, we need to do some magic to
* have all routes make sense to unlighthouse.
*
* @param url
*/
function normaliseRoute(url) {
	const { runtimeSettings, provider, resolvedConfig } = useUnlighthouse();
	if (!hasProtocol(url)) url = withBase(url, runtimeSettings.siteUrl.origin);
	const $url = new URL(url);
	const hash = $url.hash.startsWith("#/") ? $url.hash : "";
	const path$1 = `${withLeadingSlash($url.pathname)}${hash}${$url.search}`;
	let normalised = {
		id: hashPathName(path$1),
		url,
		$url,
		path: path$1
	};
	for (const matcher in resolvedConfig.scanner.customSampling) {
		if (!new RegExp(matcher).test(path$1)) continue;
		const definition = resolvedConfig.scanner.customSampling[matcher];
		normalised = {
			...normalised,
			definition: {
				...definition,
				path: path$1,
				componentBaseName: basename(definition.component || "")
			}
		};
		break;
	}
	if (!normalised.definition && provider.mockRouter && typeof provider.mockRouter !== "function") {
		const definition = provider.mockRouter.match(path$1);
		if (definition) {
			if (definition.file && !definition.component) definition.component = definition.file;
			normalised = {
				...normalised,
				definition: {
					...definition,
					componentBaseName: basename(definition.component || "")
				}
			};
		}
	}
	if (!normalised.definition) {
		const parts = trimSlashes(path$1).split("/");
		let name;
		if (path$1 === "/") name = "index";
		else if (parts.length > 1) name = parts.map((val, i) => {
			if (i >= parts.length - 1) return "slug";
			return val;
		}).join("-");
		else name = trimSlashes(path$1);
		normalised = {
			...normalised,
			definition: {
				name,
				path: path$1
			}
		};
	}
	if (normalised?.definition?.name === "index") normalised.definition.name = "_index";
	return normalised;
}

//#endregion
//#region src/util/robotsTxtParser.ts
/**
* We're going to read the robots.txt and extract any disallow or sitemaps rules from it.
*
* We're going to use the Google specification, the keys should be checked:
*
* - user-agent: identifies which crawler the rules apply to.
* - allow: a URL path that may be crawled.
* - disallow: a URL path that may not be crawled.
* - sitemap: the complete URL of a sitemap.
* - host: the host name of the site, this is optional non-standard directive.
*
* @param s robots.txt file contents
* @see https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt
*/
function parseRobotsTxt(s) {
	const groups = [];
	const sitemaps = [];
	let createNewGroup = false;
	let currentGroup = {
		comment: [],
		disallow: [],
		allow: [],
		userAgent: []
	};
	for (const line of s.split("\n")) {
		const sepIndex = line.indexOf(":");
		if (sepIndex === -1) continue;
		const rule = line.substring(0, sepIndex).trim();
		const val = line.substring(sepIndex + 1).trim();
		switch (rule) {
			case "User-agent":
				if (createNewGroup) {
					groups.push({ ...currentGroup });
					currentGroup = {
						comment: [],
						disallow: [],
						allow: [],
						userAgent: []
					};
					createNewGroup = false;
				}
				currentGroup.userAgent.push(val);
				break;
			case "Allow":
				currentGroup.allow.push(val);
				createNewGroup = true;
				break;
			case "Disallow":
				currentGroup.disallow.push(val);
				createNewGroup = true;
				break;
			case "Sitemap":
				sitemaps.push(val);
				break;
			case "Host":
				currentGroup.host = val;
				break;
		}
	}
	groups.push({ ...currentGroup });
	return {
		groups: groups.map(normalizeGroup),
		sitemaps
	};
}
function asArray(v) {
	return typeof v === "undefined" ? [] : Array.isArray(v) ? v : [v];
}
function normalizeGroup(group) {
	const disallow = asArray(group.disallow);
	const allow = asArray(group.allow).filter((rule) => Boolean(rule));
	return {
		...group,
		userAgent: group.userAgent ? asArray(group.userAgent) : ["*"],
		disallow,
		allow,
		_indexable: !disallow.includes((rule) => rule === "/"),
		_rules: [...disallow.filter(Boolean).map((r) => ({
			pattern: r,
			allow: false
		})), ...allow.map((r) => ({
			pattern: r,
			allow: true
		}))]
	};
}

//#endregion
//#region src/discovery/sitemap.ts
function validSitemapEntry(url) {
	return url && (url.startsWith("http") || url.startsWith("/"));
}
/**
* Fetches routes from a sitemap file.
*/
async function extractSitemapRoutes(site, sitemaps) {
	site = new $URL(site).origin;
	const unlighthouse = useUnlighthouse();
	const logger = useLogger();
	if (sitemaps === true || sitemaps.length === 0) sitemaps = [`${site}/sitemap.xml`];
	const sitemap = new Sitemapper({
		timeout: 15e3,
		debug: unlighthouse.resolvedConfig.debug
	});
	let paths = [];
	for (let sitemapUrl of new Set(sitemaps)) {
		logger.debug(`Attempting to fetch sitemap at ${sitemapUrl}`);
		if (!sitemapUrl.startsWith("http")) sitemapUrl = withBase(sitemapUrl, site);
		if (sitemapUrl.endsWith(".txt")) {
			const sitemapTxt = await fetchUrlRaw(sitemapUrl, unlighthouse.resolvedConfig);
			if (sitemapTxt.valid) {
				const sites = sitemapTxt.response.data.trim().split("\n").filter(validSitemapEntry);
				if (sites?.length) paths = [...paths, ...sites];
				logger.debug(`Fetched ${sitemapUrl} with ${sites.length} URLs.`);
			}
		} else {
			const { sites } = await sitemap.fetch(sitemapUrl);
			if (sites?.length) paths = [...paths, ...sites];
			logger.debug(`Fetched ${sitemapUrl} with ${sites?.length || "0"} URLs.`);
		}
	}
	const filtered = paths.filter(isScanOrigin);
	return {
		paths: filtered,
		ignored: paths.length - filtered.length,
		sitemaps
	};
}

//#endregion
//#region src/discovery/routes.ts
let warnedAboutSampling = false;
/**
* Discover the initial routes that we'll be working with.
*
* The order by preference for route discovery is as follows:
* - manual: User provided an array of URLs they want to queue
* - sitemap: We will scan their sitemap.xml to discover all of their indexable URLs
* - crawl: We process the root route and queue any discovered internal links
*/
const resolveReportableRoutes = async () => {
	const logger = useLogger();
	const { resolvedConfig, hooks, worker, routeDefinitions } = useUnlighthouse();
	const urls = new Set([]);
	if (resolvedConfig.urls?.length) {
		let urlsToAdd;
		if (typeof resolvedConfig.urls === "function") urlsToAdd = [...await resolvedConfig.urls()];
		else urlsToAdd = [...resolvedConfig.urls];
		urlsToAdd.forEach((url) => urls.add(url));
		if (urlsToAdd.length) {
			resolvedConfig.scanner.sitemap = false;
			resolvedConfig.scanner.robotsTxt = false;
			resolvedConfig.scanner.crawler = false;
			resolvedConfig.scanner.dynamicSampling = false;
			logger.info(`The \`url\` config has been provided with ${urlsToAdd.length} paths for scanning. Disabling sitemap, robots, sampling and crawler.`);
		}
	} else urls.add(resolvedConfig.site);
	if (resolvedConfig.scanner.robotsTxt) {
		const robotsTxt = await fetchRobotsTxt(resolvedConfig.site);
		if (robotsTxt) {
			const robotsTxtParsed = parseRobotsTxt(robotsTxt);
			logger.info(`Found /robots.txt, using entries. Sitemaps: ${robotsTxtParsed.sitemaps.length}, Groups: ${robotsTxtParsed.groups.length}.`);
			mergeRobotsTxtConfig(resolvedConfig, robotsTxtParsed);
		}
	}
	if (resolvedConfig.scanner.sitemap !== false) {
		const { paths: sitemapUrls, ignored, sitemaps } = await extractSitemapRoutes(resolvedConfig.site, resolvedConfig.scanner.sitemap);
		if (ignored > 0 && !sitemapUrls.length) logger.warn(`Sitemap${sitemaps.length > 1 ? "s" : ""} exists but is being ignored due to a different origin being present`);
		else if (sitemapUrls.length) {
			logger.info(`Discovered ${sitemapUrls.length} routes from ${sitemaps.length} sitemap${sitemaps.length > 1 ? "s" : ""}.`);
			if (ignored > 0) logger.warn(`Ignoring ${ignored} paths from sitemap as their origin differs from the site url.`);
			sitemapUrls.forEach((url) => urls.add(url));
			if (!resolvedConfig.site.includes("localhost") && sitemapUrls.length >= 50) {
				resolvedConfig.scanner.crawler = false;
				logger.info("Disabling crawler mode as sitemap has been provided.");
			}
		} else if (resolvedConfig.scanner.crawler) {
			resolvedConfig.scanner.sitemap = false;
			logger.info("Sitemap appears to be missing, falling back to crawler mode.");
		} else {
			resolvedConfig.scanner.sitemap = false;
			logger.error("Failed to find sitemap.xml and `routes.crawler` has been disabled. Please enable the crawler to continue scan.");
		}
	}
	if (urls.size <= 1 && routeDefinitions?.length) routeDefinitions.filter((r) => !r.path.includes(":")).map((r) => r.path).forEach((url) => urls.add(url));
	if (resolvedConfig.scanner.crawler) hooks.hook("discovered-internal-links", (path$1, internalLinks) => {
		if (path$1 === "/" && internalLinks.length <= 0 && resolvedConfig.scanner.skipJavascript) {
			resolvedConfig.scanner.skipJavascript = false;
			resolvedConfig.cache = false;
			worker.routeReports.clear();
			worker.queueRoute(normaliseRoute(path$1));
			logger.warn("No internal links discovered on home page. Switching crawler to execute javascript and disabling cache.");
			return;
		}
		worker.queueRoutes(internalLinks.map((url) => normaliseRoute(url)).map((route) => {
			route.discoveredFrom = path$1;
			return route;
		}));
	});
	const validUrls = [...urls.values()].filter((url) => isScanOrigin(url));
	if (!resolvedConfig.scanner.dynamicSampling) return validUrls.map((url) => normaliseRoute(url));
	const pathsChunkedToGroup = groupBy(validUrls.map((url) => normaliseRoute(url)), resolvedConfig.client.groupRoutesKey.replace("route.", ""));
	const pathsSampleChunkedToGroup = map(pathsChunkedToGroup, (group) => {
		const { dynamicSampling } = resolvedConfig.scanner;
		if (!dynamicSampling) return group;
		if (!warnedAboutSampling && group.length > dynamicSampling) {
			logger.warn("Dynamic sampling is in effect, some of your routes will not be scanned. To disable this behavior, set `scanner.dynamicSampling` to `false`.");
			warnedAboutSampling = true;
		}
		return sampleSize(group, dynamicSampling);
	});
	return pathsSampleChunkedToGroup.flat();
};

//#endregion
//#region src/puppeteer/cluster.ts
/**
* Create an instance of puppeteer-cluster
*/
async function launchPuppeteerCluster() {
	const { resolvedConfig } = useUnlighthouse();
	const cluster = await Cluster.launch({
		puppeteerOptions: resolvedConfig.puppeteerOptions,
		...resolvedConfig.puppeteerClusterOptions
	});
	cluster.display = {
		log() {},
		resetCursor() {}
	};
	return cluster;
}

//#endregion
//#region src/util/filter.ts
function createFilter(options = {}) {
	const include = options.include || [];
	const exclude = options.exclude || [];
	if (include.length === 0 && exclude.length === 0) return () => true;
	return function(path$1) {
		for (const v of [{
			rules: include,
			result: true
		}, {
			rules: exclude,
			result: false
		}]) {
			const regexRules = v.rules.filter((r) => r instanceof RegExp);
			if (regexRules.some((r) => r.test(path$1))) return v.result;
			const stringRules = v.rules.filter((r) => typeof r === "string");
			if (stringRules.length > 0) {
				const routes = {};
				for (const r of stringRules) {
					if (r === path$1) return v.result;
					routes[r] = true;
				}
				const routeRulesMatcher = toRouteMatcher(createRouter({
					routes,
					strictTrailingSlash: false
				}));
				if (routeRulesMatcher.matchAll(path$1).length > 0) return Boolean(v.result);
			}
		}
		return include.length === 0;
	};
}
const HTML_EXPLICIT_EXTENSIONS = [
	".html",
	".htm",
	".php",
	".asp",
	".aspx"
];
const FILE_MATCH_REGEX = /\.([0-9a-z])+$/i;
function isImplicitOrExplicitHtml(path$1) {
	const lastPathSegment = path$1.split("/").pop() || path$1;
	if (lastPathSegment.endsWith("/")) return true;
	const extension = lastPathSegment?.match(FILE_MATCH_REGEX)?.[0];
	return !extension || HTML_EXPLICIT_EXTENSIONS.includes(extension);
}

//#endregion
//#region src/puppeteer/util.ts
async function setupPage(page) {
	const { resolvedConfig, hooks } = useUnlighthouse();
	const logger = useLogger();
	const softErrorHandler = (ctx) => (err) => {
		logger.error(ctx, err);
	};
	const browser = page.browser();
	await page.setBypassCSP(true);
	if (resolvedConfig.auth) await page.authenticate(resolvedConfig.auth).catch(softErrorHandler("Failed to authenticate"));
	if (resolvedConfig.localStorage) await page.evaluateOnNewDocument((data) => {
		localStorage.clear();
		for (const key in data) localStorage.setItem(key, data[key]);
	}, resolvedConfig.localStorage);
	if (resolvedConfig.sessionStorage) await page.evaluateOnNewDocument((data) => {
		sessionStorage.clear();
		for (const key in data) sessionStorage.setItem(key, data[key]);
	}, resolvedConfig.sessionStorage);
	if (resolvedConfig.cookies) await page.setCookie(...resolvedConfig.cookies.map((cookie) => ({
		domain: resolvedConfig.site,
		...cookie
	}))).catch(softErrorHandler("Failed to set cookies"));
	if (resolvedConfig.extraHeaders) await page.setExtraHTTPHeaders(resolvedConfig.extraHeaders).catch(softErrorHandler("Failed to set extra headers"));
	browser.on("targetchanged", async (target) => {
		const page$1 = await target.page();
		if (page$1) {
			if (resolvedConfig.cookies) await page$1.setCookie(...resolvedConfig.cookies.map((cookie) => ({
				domain: resolvedConfig.site,
				...cookie
			}))).catch(softErrorHandler("Failed to set cookies"));
			if (resolvedConfig.extraHeaders) await page$1.setExtraHTTPHeaders(resolvedConfig.extraHeaders).catch(softErrorHandler("Failed to set extra headers"));
			if (resolvedConfig.userAgent) await page$1.setUserAgent(resolvedConfig.userAgent);
			await hooks.callHook("puppeteer:before-goto", page$1);
		}
	});
}

//#endregion
//#region src/puppeteer/tasks/html.ts
const extractHtmlPayload = async (page, route) => {
	const { worker, resolvedConfig } = useUnlighthouse();
	if (resolvedConfig.scanner.skipJavascript) {
		const { valid, response, redirected, redirectUrl } = await fetchUrlRaw(route, resolvedConfig);
		if (!valid || !response) return {
			success: false,
			message: `Invalid response from URL ${route} code: ${response?.status || "404"}.`
		};
		if (response.headers["content-type"] && !response.headers["content-type"].includes("text/html")) return {
			success: false,
			message: `Non-HTML Content-Type header: ${response.headers["content-type"]}.`
		};
		let htmlContent;
		if (typeof response.data === "string") htmlContent = response.data;
		else if (Buffer.isBuffer(response.data)) htmlContent = response.data.toString("utf-8");
		else if (response.data && typeof response.data === "object") htmlContent = JSON.stringify(response.data);
		else htmlContent = String(response.data || "");
		if (!htmlContent.trim()) return {
			success: false,
			message: `Empty response from URL ${route}.`
		};
		return {
			success: true,
			redirected: redirected ? redirectUrl : false,
			payload: htmlContent
		};
	}
	try {
		await page.setCacheEnabled(false);
		await page.setRequestInterception(true);
		page.on("request", (request) => {
			if ([
				"image",
				"stylesheet",
				"font",
				"other"
			].includes(request.resourceType())) request.abort();
			else request.continue();
		});
		await setupPage(page);
		const pageVisit = await page.goto(route, { waitUntil: resolvedConfig.scanner.skipJavascript ? "domcontentloaded" : "networkidle2" });
		if (!pageVisit) return {
			success: false,
			message: `Failed to go to route ${route}.`
		};
		const { "content-type": contentType, location } = pageVisit.headers();
		const statusCode = pageVisit.status();
		if ((statusCode === 301 || statusCode === 302) && location) {
			worker.queueRoute(normaliseRoute(location));
			return {
				success: false,
				message: `Redirect, queued the new URL: ${location}.`
			};
		}
		if (statusCode < 200 || statusCode >= 300) return {
			success: false,
			message: `Invalid status code: ${statusCode}.`
		};
		if (contentType && !contentType.includes("text/html")) return {
			success: false,
			message: `Invalid content-type header: ${contentType}.`
		};
		const payload = await (resolvedConfig.scanner.skipJavascript ? pageVisit.text() : page.evaluate(() => document.querySelector("*")?.outerHTML));
		return {
			success: true,
			payload
		};
	} catch (e) {
		return {
			success: false,
			message: `Exception thrown when visiting route: ${e}.`
		};
	}
};
function processSeoMeta($) {
	const hreflangElement = $("link[hreflang=\"x-default\"]");
	const hrefLangHref = hreflangElement.attr("href");
	return {
		alternativeLangDefault: hrefLangHref,
		alternativeLangDefaultHtml: hreflangElement.html() || `<link hreflang="x-default" href="${hrefLangHref}">`,
		favicon: $("link[rel~=\"icon\"]").attr("href") || "/favicon.ico",
		title: $("meta[name='title'], head > title").text(),
		description: $("meta[name='description']").attr("content"),
		og: {
			image: $("meta[property='og:image'], meta[name='og:image']").attr("content"),
			description: $("meta[property='og:description'], meta[name='og:description']").attr("content"),
			title: $("meta[property='og:title'], meta[name='og:title']").attr("content")
		}
	};
}
const inspectHtmlTask = async (props) => {
	const unlighthouse = useUnlighthouse();
	const { resolvedConfig, hooks, runtimeSettings } = unlighthouse;
	const { page, data: routeReport } = props;
	const logger = useLogger();
	let html;
	const htmlPayloadPath = join(routeReport.artifactPath, ReportArtifacts.html);
	if (resolvedConfig.cache && fs.existsSync(htmlPayloadPath)) {
		html = fs.readFileSync(htmlPayloadPath, { encoding: "utf-8" });
		logger.debug(`Running \`inspectHtmlTask\` for \`${routeReport.route.path}\` using cache.`);
	} else {
		const response = await extractHtmlPayload(page, routeReport.route.url);
		logger.debug(`HTML extract of \`${routeReport.route.url}\` response ${response.success ? "succeeded" : "failed"}.`);
		if (!response.success || !response.payload) {
			routeReport.tasks.inspectHtmlTask = "ignore";
			logger.info(`Skipping ${routeReport.route.path}. ${response.message}`);
			return routeReport;
		}
		if (response.redirected) {
			const siteHost = runtimeSettings.siteUrl.host.split(":")[0];
			const redirectHost = new URL(response.redirected).host.split(":")[0];
			if (siteHost !== redirectHost && !redirectHost.endsWith(`.${siteHost}`)) {
				routeReport.tasks.inspectHtmlTask = "ignore";
				logger.warn(`Redirected URL goes to a different domain, ignoring. \`${response.redirected}\.`);
				return routeReport;
			}
			if (withoutTrailingSlash(response.redirected) !== withoutTrailingSlash(runtimeSettings.siteUrl.href)) logger.info("Redirected url detected, this may cause issues in the final report.", response.redirected);
		}
		html = typeof response.payload === "string" ? response.payload : String(response.payload || "");
	}
	const $ = load(html);
	routeReport.seo = processSeoMeta($);
	if (resolvedConfig.scanner.ignoreI18nPages && routeReport.seo.alternativeLangDefault && withoutTrailingSlash(routeReport.route.url) !== withoutTrailingSlash(routeReport.seo.alternativeLangDefault)) {
		if (routeReport.route.path === "/") try {
			const altUrl = new URL(routeReport.seo.alternativeLangDefault);
			const siteUrl = new URL(resolvedConfig.site);
			if (altUrl.origin !== siteUrl.origin) {
				logger.warn(`Root path (/) has cross-domain hreflang alternative. Automatically disabling \`ignoreI18nPages\` to prevent all routes from being ignored. Alternative: ${routeReport.seo.alternativeLangDefault}`);
				resolvedConfig.scanner.ignoreI18nPages = false;
			}
		} catch {}
		if (resolvedConfig.scanner.ignoreI18nPages) {
			routeReport.tasks.inspectHtmlTask = "ignore";
			const newRoute = normaliseRoute(routeReport.seo.alternativeLangDefault);
			const htmlTag = routeReport.seo.alternativeLangDefaultHtml || "";
			const baseMessage = `Page has a default alternative language ${htmlTag}, ignoring \`${routeReport.route.path}\` and queueing \`${newRoute}\`.`;
			if (!unlighthouse._i18nWarn) {
				unlighthouse._i18nWarn = true;
				logger.warn(`${baseMessage}\nTo scan this page, set \`scanner.ignoreI18nPages = false\` or update --site parameter to match the hreflang origin. Future warnings will be suppressed.`);
			} else logger.debug(baseMessage);
			unlighthouse.worker.queueRoute(normaliseRoute(routeReport.seo.alternativeLangDefault));
			return routeReport;
		}
	}
	const internalLinks = [];
	const externalLinks = [];
	$("a").each(function() {
		const href = $(this).attr("href");
		if (!href || href.includes("javascript:") || href.includes("mailto:") || href === "#" || !isImplicitOrExplicitHtml(href)) return;
		if (href.startsWith("/") && !href.startsWith("//") || href.includes(resolvedConfig.site)) internalLinks.push(href);
		else externalLinks.push(href);
	});
	await hooks.callHook("discovered-internal-links", routeReport.route.path, internalLinks);
	routeReport.seo.internalLinks = internalLinks.length;
	routeReport.seo.externalLinks = externalLinks.length;
	routeReport.seo.htmlSize = html.length;
	if (resolvedConfig.cache) fs.writeFileSync(htmlPayloadPath, html);
	return routeReport;
};

//#endregion
//#region src/puppeteer/tasks/lighthouse.ts
function normaliseLighthouseResult(route, result) {
	const { resolvedConfig, runtimeSettings } = useUnlighthouse();
	const measuredCategories = Object.values(result.categories).filter((c) => typeof c.score !== "undefined");
	const columnFields = Object.values(resolvedConfig.client.columns).flat().filter((c) => !!c.key).map((c) => c.key?.replace("report.", ""));
	const imageIssues = [
		result.audits["unsized-images"],
		result.audits["preload-lcp-image"],
		result.audits["offscreen-images"],
		result.audits["modern-image-formats"],
		result.audits["uses-optimized-images"],
		result.audits["efficient-animated-content"],
		result.audits["uses-responsive-images"]
	].map((d) => (d?.details)?.items || []).flat();
	const ariaIssues = Object.values(result.audits).filter((a) => a && a.id.startsWith("aria-") && a.details?.items?.length > 0).map((a) => a.details?.items).flat();
	if (result.audits["screenshot-thumbnails"]?.details?.items) for (const k in result.audits["screenshot-thumbnails"].details.items) result.audits["screenshot-thumbnails"].details.items[k].data = relative(runtimeSettings.generatedClientPath, join(route.artifactPath, ReportArtifacts.screenshotThumbnailsDir, `${k}.jpeg`));
	return {
		categories: map(result.categories, (c, k) => {
			return {
				key: k,
				id: k,
				...pick(c, ["title", "score"])
			};
		}),
		...pick(result, [
			"fetchTime",
			"audits.redirects",
			"audits.layout-shifts",
			"audits.largest-contentful-paint-element",
			"audits.largest-contentful-paint",
			"audits.cumulative-layout-shift",
			"audits.first-contentful-paint",
			"audits.total-blocking-time",
			"audits.max-potential-fid",
			"audits.interactive",
			...columnFields
		]),
		computed: {
			imageIssues: {
				details: { items: imageIssues },
				displayValue: imageIssues.length,
				score: imageIssues.length > 0 ? 0 : 1
			},
			ariaIssues: {
				details: { items: ariaIssues },
				displayValue: ariaIssues.length,
				score: ariaIssues.length > 0 ? 0 : 1
			}
		},
		score: Math.round(sumBy(measuredCategories, "score") / measuredCategories.length * 100) / 100
	};
}
const runLighthouseTask = async (props) => {
	const logger = useLogger();
	const { resolvedConfig, runtimeSettings } = useUnlighthouse();
	const { page, data: routeReport } = props;
	const reportJsonPath = join(routeReport.artifactPath, ReportArtifacts.reportJson);
	if (resolvedConfig.cache && fs.existsSync(reportJsonPath)) try {
		const report$1 = fs.readJsonSync(reportJsonPath, { encoding: "utf-8" });
		routeReport.report = normaliseLighthouseResult(routeReport, report$1);
		return routeReport;
	} catch (e) {
		logger.warn(`Failed to read cached lighthouse report for path "${routeReport.route.path}".`, e);
	}
	await setupPage(page);
	const port = new URL(page.browser().wsEndpoint()).port;
	const clonedRouteReport = { ...routeReport };
	if (resolvedConfig.defaultQueryParams) clonedRouteReport.route.url = withQuery(clonedRouteReport.route.url, resolvedConfig.defaultQueryParams);
	const routeReportForArgs = {
		route: { url: clonedRouteReport.route.url },
		artifactPath: normalize(clonedRouteReport.artifactPath)
	};
	const args = [
		`--cache=${JSON.stringify(resolvedConfig.cache)}`,
		`--routeReport=${JSON.stringify(routeReportForArgs)}`,
		`--lighthouseOptions=${JSON.stringify(resolvedConfig.lighthouseOptions)}`,
		`--port=${port}`
	];
	const samples = [];
	for (let i = 0; i < resolvedConfig.scanner.samples; i++) try {
		const worker = (await import("execa")).execa(runtimeSettings.lighthouseProcessPath.endsWith(".ts") ? "jiti" : "node", [runtimeSettings.lighthouseProcessPath, ...args], { timeout: 6 * 60 * 1e3 });
		worker.stdout.pipe(process.stdout);
		worker.stderr.pipe(process.stderr);
		const res = await worker;
		if (res) samples.push(fs.readJsonSync(reportJsonPath));
	} catch (e) {
		logger.error("Failed to run lighthouse for route", e);
		return routeReport;
	}
	let report = samples[0];
	if (!report) {
		logger.error(`Task \`runLighthouseTask\` has failed to run for path "${routeReport.route.path}".`);
		routeReport.tasks.runLighthouseTask = "failed";
		return routeReport;
	}
	if (report.categories.performance && !report.categories.performance.score) {
		logger.warn(`Lighthouse failed to run performance audits for "${routeReport.route.path}", adding back to queue${report.runtimeError ? `: ${report.runtimeError.message}` : "."}`);
		routeReport.tasks.runLighthouseTask = "failed-retry";
		return routeReport;
	}
	if (samples.length > 1) try {
		report = computeMedianRun(samples);
	} catch (e) {
		logger.warn("Error when computing median score, possibly audit failed.", e);
	}
	if (report.audits?.["final-screenshot"]?.details?.data) await fs.writeFile(join(routeReport.artifactPath, ReportArtifacts.screenshot), base64ToBuffer(report.audits["final-screenshot"].details.data));
	if (report.fullPageScreenshot?.screenshot.data) await fs.writeFile(join(routeReport.artifactPath, ReportArtifacts.fullScreenScreenshot), base64ToBuffer(report.fullPageScreenshot.screenshot.data));
	const screenshotThumbnails = report.audits?.["screenshot-thumbnails"]?.details;
	await fs.mkdir(join(routeReport.artifactPath, ReportArtifacts.screenshotThumbnailsDir), { recursive: true });
	if (screenshotThumbnails?.items && screenshotThumbnails.type === "filmstrip") for (const key in screenshotThumbnails.items) {
		const thumbnail = screenshotThumbnails.items[key];
		await fs.writeFile(join(routeReport.artifactPath, ReportArtifacts.screenshotThumbnailsDir, `${key}.jpeg`), base64ToBuffer(thumbnail.data));
	}
	routeReport.report = normaliseLighthouseResult(routeReport, report);
	return routeReport;
};

//#endregion
//#region src/util/progressBox.ts
/**
* Create a progress box that displays scanning progress using Clack spinner
*/
function createProgressBox() {
	let clackSpinner;
	const update = (progressData) => {
		if (!clackSpinner && progressData.totalTasks > 0) {
			clackSpinner = p.spinner();
			clackSpinner.start("Starting scan...");
		}
		if (clackSpinner && progressData.totalTasks > 0) {
			const percentage = Math.round(progressData.completedTasks / progressData.totalTasks * 100);
			const formatTime = (ms) => {
				const minutes = Math.floor(ms / 6e4);
				const seconds = Math.floor(ms % 6e4 / 1e3);
				if (minutes > 60) {
					const hours = Math.floor(minutes / 60);
					const remainingMins = minutes % 60;
					return `${hours}h ${remainingMins}m`;
				}
				return minutes > 0 ? `${minutes}m ${seconds}s` : `${seconds}s`;
			};
			const formatScore = (score) => {
				if (score === void 0) return "calculating...";
				const rounded = Math.round(score * 100);
				return `${rounded}/100`;
			};
			let message = `${percentage}% (${progressData.completedTasks}/${progressData.totalTasks})`;
			if (progressData.averageScore !== void 0) message += ` â€¢ Score: ${formatScore(progressData.averageScore)}`;
			message += ` â€¢ ${formatTime(progressData.timeElapsed)}`;
			if (progressData.timeRemaining && progressData.timeRemaining > 0) message += ` â€¢ ETA: ${formatTime(progressData.timeRemaining)}`;
			if (progressData.currentTask) {
				const currentTask = progressData.currentTask.length > 50 ? `${progressData.currentTask.substring(0, 47)}...` : progressData.currentTask;
				message += ` â€¢ ${currentTask}`;
			}
			clackSpinner.message(message);
		}
	};
	const clear = () => {
		if (clackSpinner) {
			clackSpinner.stop("Scan completed!");
			clackSpinner = void 0;
		}
	};
	return {
		update,
		clear
	};
}

//#endregion
//#region src/puppeteer/worker.ts
let warnedMaxRoutesExceeded = false;
/**
* The unlighthouse worker is a wrapper for the puppeteer-cluster. It handles the queuing of the tasks with more control
* over the clusters monitoring and queue management while providing a tight integration with unlighthouse.
*
* @param tasks
*/
async function createUnlighthouseWorker(tasks) {
	const { hooks, resolvedConfig } = useUnlighthouse();
	const logger = useLogger();
	const progressBox = createProgressBox();
	const cluster = await launchPuppeteerCluster();
	const routeReports = new Map();
	const ignoredRoutes = new Set();
	const retriedRoutes = new Map();
	const taskCompletionTimes = new Map();
	const startTime = Date.now();
	let currentTaskInfo = "";
	const monitor = () => {
		const now = Date.now();
		const timeDiff = now - cluster.startTime;
		const doneTargets = cluster.allTargetCount - cluster.jobQueue.size() - cluster.workersBusy.length;
		const donePercentage = cluster.allTargetCount === 0 ? 1 : doneTargets / cluster.allTargetCount;
		const donePercStr = (100 * donePercentage).toFixed(0);
		const errorPerc = doneTargets === 0 ? "0.00" : (100 * cluster.errorCount / doneTargets).toFixed(2);
		const timeRunning = timeDiff;
		let timeRemainingMillis = -1;
		if (donePercentage !== 0) {
			const taskDurations = {
				inspectHtmlTask: [],
				runLighthouseTask: []
			};
			for (const [, completionTimes] of taskCompletionTimes) for (const taskName of Object.keys(tasks)) {
				const duration = completionTimes[taskName];
				if (duration) taskDurations[taskName].push(duration);
			}
			const avgInspectTime = taskDurations.inspectHtmlTask.length > 0 ? taskDurations.inspectHtmlTask.reduce((a, b) => a + b, 0) / taskDurations.inspectHtmlTask.length : 2e3;
			const avgLighthouseTime = taskDurations.runLighthouseTask.length > 0 ? taskDurations.runLighthouseTask.reduce((a, b) => a + b, 0) / taskDurations.runLighthouseTask.length : 15e3;
			let remainingInspectTasks = 0;
			let remainingLighthouseTasks = 0;
			for (const report of routeReports.values()) for (const taskName of Object.keys(tasks)) {
				const taskStatus = report.tasks[taskName];
				if (taskStatus === "waiting" || taskStatus === "in-progress") {
					if (taskName === "inspectHtmlTask") remainingInspectTasks++;
					else if (taskName === "runLighthouseTask") remainingLighthouseTasks++;
				}
			}
			const estimatedRemainingTime = remainingInspectTasks * avgInspectTime + remainingLighthouseTasks * avgLighthouseTime;
			timeRemainingMillis = Math.round(estimatedRemainingTime);
			if (remainingInspectTasks === 0 && remainingLighthouseTasks === 0) timeRemainingMillis = Math.round(timeDiff / donePercentage - timeDiff);
		}
		const timeRemaining = timeRemainingMillis;
		const cpuUsage = `${cluster.systemMonitor.getCpuUsage().toFixed(1)}%`;
		const memoryUsage = `${cluster.systemMonitor.getMemoryUsage().toFixed(1)}%`;
		const pagesPerSecond = doneTargets === 0 ? "0" : (doneTargets * 1e3 / timeDiff).toFixed(2);
		return {
			status: cluster.allTargetCount === doneTargets ? "completed" : "working",
			timeRunning,
			doneTargets,
			allTargets: cluster.allTargetCount,
			donePercStr,
			errorPerc,
			timeRemaining,
			pagesPerSecond,
			cpuUsage,
			memoryUsage,
			workers: cluster.workers.length + cluster.workersStarting
		};
	};
	const updateProgressDisplay = () => {
		if (!process.stdin.isTTY) return;
		const stats = monitor();
		const completedReports = routeReports.size > 0 ? [...routeReports.values()].filter((r) => Object.values(r.tasks).every((status) => status === "completed" || status === "ignore" || status === "failed")) : [];
		const scoresFromReports = completedReports.map((r) => r.report?.score).filter((score) => typeof score === "number");
		const averageScore = scoresFromReports.length > 0 ? scoresFromReports.reduce((sum, score) => sum + score, 0) / scoresFromReports.length : void 0;
		const progressData = {
			currentTask: currentTaskInfo,
			completedTasks: stats.doneTargets,
			totalTasks: stats.allTargets,
			averageScore,
			timeElapsed: Date.now() - startTime,
			timeRemaining: stats.timeRemaining > 0 ? stats.timeRemaining : void 0
		};
		progressBox.update(progressData);
	};
	const exceededMaxRoutes = () => {
		return resolvedConfig.scanner.maxRoutes !== false && routeReports.size >= resolvedConfig.scanner.maxRoutes;
	};
	const queueRoute = (route) => {
		const { id, path: path$1 } = route;
		if (exceededMaxRoutes()) {
			if (!warnedMaxRoutesExceeded) {
				logger.warn(`You have reached the \`scanner.maxRoutes\` limit of ${resolvedConfig.scanner.maxRoutes}. No further routes will be queued, consider raising this limit.`);
				warnedMaxRoutesExceeded = true;
				return;
			}
			return;
		}
		if (routeReports.has(id)) return;
		if (ignoredRoutes.has(id)) return;
		if (resolvedConfig.scanner.robotsTxt && resolvedConfig.scanner._robotsTxtRules?.length) {
			const rule = matchPathToRule(path$1, resolvedConfig.scanner._robotsTxtRules);
			if (rule && !rule.allow) {
				logger.info(`Skipping route based on robots.txt rule \`${rule.pattern}\``, { path: path$1 });
				return;
			}
		}
		if (resolvedConfig.scanner.include || resolvedConfig.scanner.exclude) {
			const filter = createFilter(resolvedConfig.scanner);
			if (!filter(path$1)) {
				logger.info("Skipping route based on include / exclude rules", {
					path: path$1,
					include: resolvedConfig.scanner.include,
					exclude: resolvedConfig.scanner.exclude
				});
				return;
			}
		}
		if (!isImplicitOrExplicitHtml(path$1)) {
			logger.debug("Skipping non-HTML file from scanning", { path: path$1 });
			return;
		}
		if (resolvedConfig.scanner.dynamicSampling && resolvedConfig.scanner.dynamicSampling > 0) {
			const routeGroup = get(route, resolvedConfig.client.groupRoutesKey.replace("route.", ""));
			const routesInGroup = [...routeReports.values()].filter((r) => get(r, resolvedConfig.client.groupRoutesKey) === routeGroup).length;
			if (routesInGroup >= resolvedConfig.scanner.dynamicSampling) return;
		}
		const routeReport = createTaskReportFromRoute(route);
		logger.debug(`Route has been queued. Path: \`${path$1}\` Name: ${routeReport.route.definition?.name}.`);
		routeReports.set(id, routeReport);
		hooks.callHook("task-added", path$1, routeReport);
		updateProgressDisplay();
		const runTaskIndex = (idx = 0) => {
			const taskName = Object.keys(tasks)?.[idx];
			if (!taskName) {
				if (monitor().status === "completed") hooks.callHook("worker-finished");
				return;
			}
			const task = Object.values(tasks)[idx];
			routeReport.tasks[taskName] = "waiting";
			cluster.execute(routeReport, (arg) => {
				routeReport.tasks[taskName] = "in-progress";
				routeReport.tasksTime = routeReport.tasksTime || {};
				routeReport.tasksTime[taskName] = Date.now();
				currentTaskInfo = `${taskName.replace("Task", "")} - ${path$1}`;
				updateProgressDisplay();
				hooks.callHook("task-started", path$1, routeReport);
				return task(arg);
			}).then((response) => {
				if (response.tasks[taskName] === "ignore") {
					routeReports.delete(id);
					ignoredRoutes.add(id);
					logger.debug(`Ignoring route \`${routeReport.route.path}\`.`);
					if (monitor().status === "completed") hooks.callHook("worker-finished");
					return;
				}
				if (response.tasks[taskName] === "failed") return;
				if (response.tasks[taskName] === "failed-retry") {
					const currentRetries = retriedRoutes.get(id) || 0;
					logger.debug(`Route "${path$1}" (id: ${id}) failed, retry attempt ${currentRetries + 1}/3`);
					if (currentRetries < 3) {
						retriedRoutes.set(id, currentRetries + 1);
						requeueReport(routeReport);
					} else {
						logger.warn(`Route "${path$1}" has exceeded maximum retry attempts (3), skipping.`);
						response.tasks[taskName] = "failed";
						routeReports.set(id, response);
					}
					return;
				}
				response.tasks[taskName] = "completed";
				routeReports.set(id, response);
				hooks.callHook("task-complete", path$1, response, taskName);
				const ms = Date.now() - routeReport.tasksTime?.[taskName];
				if (!taskCompletionTimes.has(id)) taskCompletionTimes.set(id, {});
				taskCompletionTimes.get(id)[taskName] = ms;
				const seconds = (ms / 1e3).toFixed(1);
				const reportData = [`Time Taken: ${seconds}s`];
				if (taskName === "runLighthouseTask") {
					if (response.report?.score) reportData.push(`Score: ${response.report.score}`);
					if (resolvedConfig.scanner.samples) reportData.push(`Samples: ${resolvedConfig.scanner.samples}`);
				} else if (taskName === "inspectHtmlTask") {
					if (response.seo.htmlSize) reportData.push(formatBytes(response.seo.htmlSize));
				}
				reportData.push(`${monitor().donePercStr}% complete`);
				updateProgressDisplay();
				runTaskIndex(idx + 1);
			});
		};
		runTaskIndex();
	};
	const queueRoutes = (routes) => {
		routes = uniqBy(routes, "path");
		const sortedRoutes = sortBy(routes, (r) => {
			if (resolvedConfig.discovery && r.definition) return get(r, resolvedConfig.client.groupRoutesKey.replace("route.", ""));
			return r.path;
		});
		sortedRoutes.forEach((route) => queueRoute(route));
	};
	const requeueReport = (report) => {
		const currentRetries = retriedRoutes.get(report.route.id) || 0;
		logger.info(`Submitting \`${report.route.path}\` for a re-queue (attempt ${currentRetries}/3).`);
		Object.values(ReportArtifacts).forEach((artifact) => {
			fs$1.rmSync(join(report.artifactPath, artifact), {
				force: true,
				recursive: true
			});
		});
		routeReports.delete(report.reportId);
		setTimeout(() => {
			queueRoute(report.route);
		}, 3500);
	};
	const hasStarted = () => cluster.workers.length || cluster.workersStarting;
	const reports = () => [...routeReports.values()];
	const invalidateFile = (file) => {
		if (file.startsWith(resolvedConfig.outputPath)) return false;
		const matched = reports().filter((r) => r.route.definition.component === file || r.route.definition.component?.endsWith(file));
		if (matched.length) {
			logger.info(`Invalidating file ${file}, matched ${matched.length} routes.`);
			matched.forEach((r) => requeueReport(r));
			return true;
		}
		return false;
	};
	const findReport = (id) => reports().filter((report) => report.reportId === id)?.[0];
	return {
		cluster,
		routeReports,
		exceededMaxRoutes,
		requeueReport,
		invalidateFile,
		queueRoute,
		queueRoutes,
		findReport,
		monitor,
		hasStarted,
		reports,
		clearProgressDisplay: () => progressBox.clear()
	};
}

//#endregion
//#region src/resolveConfig.ts
/**
* A provided configuration from the user may require runtime transformations to avoid breaking app functionality.
*
* Mostly normalisation of data and provided sane runtime defaults when configuration hasn't been fully provided, also
* includes configuration alias helpers though such as `scanner.throttle`.
*
* @param userConfig
*/
const resolveUserConfig = async (userConfig) => {
	const logger = useLogger();
	const merger = createDefu((obj, key, value) => {
		if ((key === "supportedExtensions" || key === "onlyCategories") && value) {
			obj[key] = value;
			return true;
		}
	});
	const config = merger(userConfig, defaultConfig);
	if (!config.site && Array.isArray(config.urls) && config.urls?.[0]) config.site = config.urls[0];
	if (config.site) {
		const siteUrl = normaliseHost(config.site);
		if (siteUrl.pathname !== "/" && siteUrl.pathname !== "") {
			logger.warn("You are providing a site with a path, disabling sitemap, robots and dynamic sampling.");
			config.scanner = config.scanner || {};
			config.scanner.sitemap = false;
			config.scanner.robotsTxt = false;
			config.scanner.dynamicSampling = false;
			config.site = siteUrl.toString();
		} else config.site = siteUrl.origin;
	}
	if (config.lighthouseOptions) {
		if (config.lighthouseOptions.onlyCategories?.length) if (config.lighthouseOptions.onlyAudits?.length) {
			logger.warn("You have specified both `onlyCategories` and `onlyAudits`. `onlyCategories` will be ignored.");
			config.lighthouseOptions.onlyCategories = [];
		} else config.lighthouseOptions.onlyCategories = defaultConfig.lighthouseOptions.onlyCategories.filter((column) => config.lighthouseOptions.onlyCategories.includes(column));
	} else config.lighthouseOptions = {};
	if (typeof config.lighthouseOptions.throttlingMethod === "undefined" && typeof config.lighthouseOptions.throttling === "undefined") {
		if (typeof config.scanner?.throttle) {
			config.lighthouseOptions.throttlingMethod = "simulate";
			config.lighthouseOptions.throttling = {
				rttMs: 150,
				throughputKbps: 1.6 * 1024,
				requestLatencyMs: 150 * 4,
				downloadThroughputKbps: 1.6 * 1024,
				uploadThroughputKbps: 750,
				cpuSlowdownMultiplier: 1
			};
		} else if (!config.site || config.site.includes("localhost") || config.scanner?.throttle === false) {
			config.lighthouseOptions.throttlingMethod = "provided";
			config.lighthouseOptions.throttling = {
				rttMs: 0,
				throughputKbps: 0,
				cpuSlowdownMultiplier: 1,
				requestLatencyMs: 0,
				downloadThroughputKbps: 0,
				uploadThroughputKbps: 0
			};
		}
	}
	config.scanner.exclude = config.scanner?.exclude || [];
	config.scanner.exclude.push("/cdn-cgi/*");
	config.chrome = defu(config.chrome || {}, {
		useSystem: true,
		useDownloadFallback: true,
		downloadFallbackCacheDir: join(homedir(), ".unlighthouse")
	});
	if (config.auth) {
		config.lighthouseOptions.extraHeaders = config.lighthouseOptions.extraHeaders || {};
		if (!config.lighthouseOptions.extraHeaders.Authorization) {
			const credentials = `${config.auth.username}:${config.auth.password}`;
			config.lighthouseOptions.extraHeaders.Authorization = `Basic ${Buffer.from(credentials).toString("base64")}`;
		}
	}
	if (config.client?.columns) config.client.columns = pick(config.client.columns, ["overview", ...config.lighthouseOptions.onlyCategories]);
	if (config.root && config.discovery && config.discovery.pagesDir === "pages") {
		const pagesDirExist = await pathExists(join(config.root, config.discovery.pagesDir));
		if (!pagesDirExist) {
			logger.debug("Unable to locale page files, disabling route discovery.");
			config.discovery = false;
		}
	}
	config.lighthouseOptions.formFactor = config.lighthouseOptions.formFactor || config.scanner?.device || "mobile";
	if (config.lighthouseOptions.formFactor === "desktop") config.lighthouseOptions.screenEmulation = {
		mobile: false,
		width: 1350,
		height: 940,
		deviceScaleFactor: 1,
		disabled: false
	};
	else config.lighthouseOptions.screenEmulation = {
		mobile: true,
		width: 412,
		height: 823,
		deviceScaleFactor: 1.75,
		disabled: false
	};
	if (!config.lighthouseOptions.emulatedUserAgent) if (config.lighthouseOptions.formFactor === "mobile") config.lighthouseOptions.emulatedUserAgent = "Mozilla/5.0 (Linux; Android 11; moto g power (2022)) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Mobile Safari/537.36";
	else config.lighthouseOptions.emulatedUserAgent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36";
	if (userConfig.extraHeaders) config.lighthouseOptions.extraHeaders = userConfig.extraHeaders;
	if (config.routerPrefix) config.routerPrefix = withSlashes(config.routerPrefix);
	config.puppeteerOptions = defu(config.puppeteerOptions, {
		timeout: 0,
		protocolTimeout: 0
	});
	config.puppeteerClusterOptions = defu(config.puppeteerClusterOptions, { timeout: 12e4 });
	config.puppeteerOptions = defu(config.puppeteerOptions, {
		headless: true,
		ignoreHTTPSErrors: true
	});
	config.puppeteerOptions.defaultViewport = config.lighthouseOptions.screenEmulation;
	let foundChrome = !!config.puppeteerOptions?.executablePath;
	if (config.chrome.useSystem && !foundChrome) {
		let chromePath = false;
		try {
			chromePath = Launcher.getFirstInstallation();
		} catch (e) {
			logger.debug("Chrome launcher failed to get a path.", e);
		}
		if (chromePath) {
			logger.info(`Using system Chrome located at: \`${chromePath}\`.`);
			config.puppeteerClusterOptions.puppeteer = puppeteer;
			config.puppeteerOptions.executablePath = chromePath;
			foundChrome = true;
		}
	}
	if (foundChrome) {
		logger.debug("Testing system Chrome installation.");
		const instance$1 = await launch$1(config.puppeteerOptions).catch((e) => {
			logger.warn(`Failed to launch puppeteer instance using \`${config.puppeteerOptions?.executablePath}\`.`, e);
			foundChrome = false;
		});
		if (instance$1) await instance$1.close();
	}
	if (!foundChrome) try {
		await resolve$1("puppeteer");
		foundChrome = true;
		logger.info("Using puppeteer dependency for Chrome.");
	} catch (e) {
		logger.debug("Puppeteer does not exist as a dependency.", e);
	}
	if (config.chrome.useDownloadFallback && !foundChrome) {
		const browserOptions = {
			installDeps: process.getuid?.() === 0,
			cacheDir: config.chrome.downloadFallbackCacheDir,
			buildId: config.chrome.downloadFallbackVersion || PUPPETEER_REVISIONS.chrome,
			browser: "chrome"
		};
		const chromePath = computeExecutablePath(browserOptions);
		if (!existsSync(chromePath)) {
			logger.info(`Missing ${browserOptions.browser} binary, downloading v${browserOptions.buildId}...`);
			let lastPercent = 0;
			await install({
				...browserOptions,
				downloadProgressCallback: (downloadedBytes, toDownloadBytes) => {
					const percent = Math.round(downloadedBytes / toDownloadBytes * 100);
					if (percent % 5 === 0 && lastPercent !== percent) {
						logger.info(`Downloading ${browserOptions.browser}: ${percent}%`);
						lastPercent = percent;
					}
				}
			});
		}
		logger.info(`Using downloaded ${browserOptions.browser} v${browserOptions.buildId} located at: ${chromePath}`);
		config.puppeteerOptions.executablePath = chromePath;
		foundChrome = true;
	}
	if (!foundChrome) throw new Error("Failed to find chrome. Please ensure you have a valid chrome installed.");
	const instance = await launch$1(config.puppeteerOptions).catch((e) => {
		if (detectBrowserPlatform() === "linux" && e.toString().includes("error while loading shared libraries")) {
			const depsPath = path.join(path.dirname(config.puppeteerOptions.executablePath), "deb.deps");
			if (existsSync(depsPath)) {
				const data = readFileSync(depsPath, "utf-8").trim().split("\n").map((d) => `"${d}"`).join(",");
				logger.warn("Failed to start puppeteer, you may be missing dependencies.");
				logger.log("");
				const command = [
					"sudo",
					"apt-get",
					"satisfy",
					"-y",
					data,
					"--no-install-recommends"
				].join(" ");
				console.log(`\x1B[96m%s\x1B[0m`, `Run the following command:\n${command}`);
				logger.log("");
			}
		}
		throw e;
	});
	if (instance) await instance.close();
	config.outputPath = resolve(config.root, config.outputPath);
	return config;
};

//#endregion
//#region src/util/cliFormatting.ts
/**
* Copied from https://github.com/nuxt/nuxt.js/blob/dev/packages/cli/src/utils/formatting.js
*/
const maxCharsPerLine = () => (process.stdout.columns || 100) * 80 / 100;
function indent(count, chr = " ") {
	return chr.repeat(count);
}
function indentLines(string, spaces, firstLineSpaces) {
	const lines = Array.isArray(string) ? string : string.split("\n");
	let s = "";
	if (lines.length) {
		const i0 = indent(firstLineSpaces === void 0 ? spaces : firstLineSpaces);
		s = i0 + lines.shift();
	}
	if (lines.length) {
		const i = indent(spaces);
		s += `\n${lines.map((l) => i + l).join("\n")}`;
	}
	return s;
}
function foldLines(string, spaces, firstLineSpaces, charsPerLine = maxCharsPerLine()) {
	return indentLines(wrapAnsi(string, charsPerLine), spaces, firstLineSpaces);
}
function box$1(message, title, options) {
	return `${box([
		title,
		"",
		colorize("white", foldLines(message, 0, 0, maxCharsPerLine()))
	].join("\n"), Object.assign({
		borderColor: "white",
		borderStyle: "round",
		padding: 1,
		margin: 1
	}, options))}\n`;
}
function successBox(message, title) {
	return box$1(message, title, { style: { borderColor: "green" } });
}

//#endregion
//#region src/unlighthouse.ts
const engineContext = createContext();
/**
* Use the unlighthouse instance.
*/
const useUnlighthouse = engineContext.tryUse;
/**
* A simple define wrapper to provide typings to config definitions.
* @deprecated Use `defineUnlighthouseConfig` from `unlighthouse/config` instead.
*/
function defineConfig(config) {
	return config;
}
/**
* Create a unique single unlighthouse instance that can be referenced globally with `useUnlighthouse()`. Scanning will
* not start automatically, a server context needs to be provided using `setServerContext()`.
*
* @param userConfig
* @param provider
*/
async function createUnlighthouse(userConfig, provider) {
	const logger = createLogger(userConfig.debug);
	const { __dirname } = createCommonJS(import.meta.url);
	if (userConfig.root && !isAbsolute(userConfig.root)) userConfig.root = join(process.cwd(), userConfig.root);
	else if (!userConfig.root) userConfig.root = process.cwd();
	logger.debug(`Starting Unlighthouse at root: \`${userConfig.root}\` cwd: ${process.cwd()}`);
	globalThis.defineUnlighthouseConfig = (c) => c;
	const { configFile, config } = await loadConfig({
		name: "unlighthouse",
		configFile: userConfig.configFile || "unlighthouse.config",
		dotenv: true
	});
	delete globalThis.defineUnlighthouseConfig;
	logger.debug("Discovered config definition", config);
	userConfig = defu(config, userConfig);
	const runtimeSettings = {
		configFile: configFile || void 0,
		moduleWorkingDir: __dirname,
		configCacheKey: "",
		lighthouseProcessPath: ""
	};
	runtimeSettings.lighthouseProcessPath = await resolvePath(join(runtimeSettings.moduleWorkingDir, "lighthouse.mjs")).catch(() => "");
	if (!await fs.pathExists(runtimeSettings.lighthouseProcessPath)) runtimeSettings.lighthouseProcessPath = await resolvePath(join(runtimeSettings.moduleWorkingDir, "lighthouse.ts"));
	runtimeSettings.configCacheKey = objectHash({
		...userConfig,
		version
	}).substring(0, 4);
	const resolvedConfig = await resolveUserConfig(userConfig);
	logger.debug("Post config resolution", resolvedConfig);
	const hooks = createHooks();
	if (resolvedConfig.hooks) hooks.addHooks(resolvedConfig.hooks);
	await hooks.callHook("resolved-config", resolvedConfig);
	if (configFile) logger.info(`Creating Unlighthouse ${configFile ? `using config from \`${configFile}\`` : ""}`);
	const ws = provider?.name === "ci" ? null : new WS();
	const ctx = {
		runtimeSettings,
		hooks,
		resolvedConfig,
		ws,
		provider
	};
	engineContext.set(ctx, true);
	const tasks = {
		inspectHtmlTask,
		runLighthouseTask
	};
	const worker = await createUnlighthouseWorker(tasks);
	if (resolvedConfig.hooks?.authenticate) await worker.cluster.execute({}, async (taskCtx) => {
		logger.debug("Running authentication hook");
		await taskCtx.page.setBypassCSP(true);
		await hooks.callHook("authenticate", taskCtx.page);
		const localStorageData = await taskCtx.page.evaluate(() => {
			const json = {};
			for (let i = 0; i < localStorage.length; i++) {
				const key = localStorage.key(i);
				if (key) json[key] = localStorage.getItem(key);
			}
			return json;
		}).catch((e) => {
			logger.warn("Failed to collect authentication localStorage.\n", e);
			return {};
		});
		const sessionStorageData = await taskCtx.page.evaluate(() => {
			const json = {};
			for (let i = 0; i < sessionStorage.length; i++) {
				const key = sessionStorage.key(i);
				if (key) json[key] = sessionStorage.getItem(key);
			}
			return json;
		}).catch((e) => {
			logger.warn("Failed to collect authentication sessionStorage.\n", e);
			return {};
		});
		const cookies = await taskCtx.page.cookies();
		logger.debug("Authentication completed", {
			cookies,
			localStorageData,
			sessionStorageData
		});
		ctx.resolvedConfig.cookies = [...ctx.resolvedConfig.cookies || [], ...cookies];
		ctx.resolvedConfig.localStorage = {
			...ctx.resolvedConfig.localStorage,
			...localStorageData
		};
		ctx.resolvedConfig.sessionStorage = {
			...ctx.resolvedConfig.sessionStorage,
			...sessionStorageData
		};
	});
	ctx.worker = worker;
	ctx.setCiContext = async () => {
		const $site = new $URL(resolvedConfig.site);
		logger.debug(`Setting Unlighthouse CI Context [Site: ${$site}]`);
		let outputPath = join(resolvedConfig.outputPath, $site.hostname.replace(":", "êž‰"), runtimeSettings.configCacheKey || "");
		try {
			await fs.mkdir(resolvedConfig.outputPath, { recursive: true });
		} catch (e) {
			logger.error(`Failed to create output directory. Please check unlighthouse has permissions to: ${resolvedConfig.outputPath}`, e);
		}
		try {
			await fs.mkdir(outputPath, { recursive: true });
		} catch (e) {
			logger.error(`Failed to create output directory. Please check unlighthouse has permission to create files and folders in: ${resolvedConfig.outputPath}`, e);
		}
		if (provider?.name === "ci") outputPath = resolvedConfig.outputPath;
		ctx.runtimeSettings = {
			...ctx.runtimeSettings,
			outputPath,
			generatedClientPath: outputPath,
			resolvedClientPath: await resolvePath(ClientPkg, { url: import.meta.url })
		};
		if (!resolvedConfig.cache && existsSync(resolvedConfig.outputPath)) {
			logger.debug(`\`cache\` is disabled, deleting cache folder: \`${resolvedConfig.outputPath}\``);
			fs.rmSync(outputPath, { recursive: true });
		}
		fs.ensureDirSync(ctx.runtimeSettings.outputPath);
		return ctx;
	};
	ctx.setSiteUrl = async (url) => {
		const site = normaliseHost(url);
		ctx.runtimeSettings.siteUrl = site;
		logger.debug(`Setting Unlighthouse Site URL [Site: ${site.toString()}]`);
		const outputPath = join(resolvedConfig.outputPath, runtimeSettings.siteUrl?.hostname.replace(":", "êž‰") || "", runtimeSettings.configCacheKey || "");
		if (!ctx.resolvedConfig.site) ctx.resolvedConfig.site = site.toString();
		ctx.runtimeSettings.outputPath = outputPath;
		ctx.runtimeSettings.generatedClientPath = outputPath;
		await hooks.callHook("site-changed", ctx.resolvedConfig.site);
	};
	ctx.setServerContext = async ({ url, server, app }) => {
		const $server = new URL(url);
		logger.debug(`Setting Unlighthouse Server Context [Server: ${$server}]`);
		const clientUrl = joinURL($server.toString(), resolvedConfig.routerPrefix);
		const apiPath = joinURL(resolvedConfig.routerPrefix, resolvedConfig.apiPrefix);
		ctx.runtimeSettings.serverUrl = url;
		ctx.runtimeSettings = {
			...ctx.runtimeSettings,
			apiPath,
			server,
			resolvedClientPath: await resolvePath(ClientPkg, { url: import.meta.url }),
			clientUrl,
			apiUrl: joinURL($server.toString(), apiPath),
			websocketUrl: `ws://${joinURL($server.host, apiPath, "/ws")}`
		};
		ctx.api = await createApi(app);
		if (ws) server.on("upgrade", (request, socket) => {
			ws.handleUpgrade(request, socket);
		});
		if (!resolvedConfig.cache && existsSync(ctx.runtimeSettings.outputPath)) {
			logger.debug(`\`cache\` is disabled, deleting cache folder: \`${ctx.runtimeSettings.outputPath}\``);
			try {
				fs.rmSync(ctx.runtimeSettings.outputPath, { recursive: true });
			} catch (e) {
				logger.debug(`Failed to delete cache folder: \`${ctx.runtimeSettings.outputPath}\``, e);
			}
		}
		fs.ensureDirSync(ctx.runtimeSettings.outputPath);
		await generateClient();
		if (provider?.name !== "cli") hooks.hookOnce("visited-client", () => {
			ctx.start();
		});
		return ctx;
	};
	ctx.start = async () => {
		logger.debug(`Starting Unlighthouse [Server: ${provider?.name === "ci" ? "N/A" : ctx.runtimeSettings.clientUrl} Site: ${ctx.resolvedConfig.site} Debug: \`${ctx.resolvedConfig.debug}\`]`);
		if (typeof provider?.routeDefinitions === "function") ctx.routeDefinitions = await provider.routeDefinitions();
		else ctx.routeDefinitions = provider?.routeDefinitions;
		if (!ctx.routeDefinitions && resolvedConfig.discovery !== false) {
			logger.debug("No route definitions provided, discovering them ourselves.");
			ctx.routeDefinitions = await discoverRouteDefinitions();
		}
		if (ctx.routeDefinitions?.length) {
			ctx.provider = ctx.provider || {};
			if (typeof ctx.provider?.mockRouter === "function") ctx.provider.mockRouter = ctx.provider.mockRouter(ctx.routeDefinitions);
			else if (!ctx.provider.mockRouter) ctx.provider.mockRouter = createMockRouter(ctx.routeDefinitions);
			logger.debug(`Discovered ${ctx.routeDefinitions?.length} definitions and setup mock router.`);
		}
		ctx.routes = await resolveReportableRoutes();
		logger.debug("Resolved reportable routes", ctx.routes.length);
		createBroadcastingEvents();
		if (provider?.name !== "ci") {
			const label = (name) => colorize("bold", colorize("magenta", `â–¸ ${name}:`));
			let mode = "";
			if (resolvedConfig.urls?.length) mode = "Manual";
			if (resolvedConfig.scanner.sitemap !== false) mode += "Sitemap";
			if (resolvedConfig.scanner.crawler) mode += mode.length > 0 ? " + Crawler" : "Crawler";
			let latestTag = `v${version}`;
			try {
				latestTag = (await $fetch("https://ungh.unjs.io/repos/harlan-zw/unlighthouse/releases/latest")).release.tag;
			} catch {}
			const title = [`â›µ\u200D  ${colorize("bold", colorize("blueBright", AppName))} ${colorize("dim", `${provider?.name} @ v${version}`)}`];
			if (Number(latestTag.replace("v", "").replace(".", "")) > Number(version.replace(".", ""))) title.push(...[
				"",
				`ðŸŽ‰ New version ${latestTag} available! Use the latest:`,
				colorize("gray", ` > ${colorize("underline", `npx unlighthouse@^${latestTag} --site ${resolvedConfig.site}`)}`)
			]);
			title.push(...[
				"",
				`${label("Scanning")} ${resolvedConfig.site}`,
				`${label("Route Discovery")} ${mode} ${ctx.routes.length > 1 ? colorize("dim", `${ctx.routes.length} initial URLs`) : ""}`
			]);
			if (ctx.routeDefinitions?.length) title.push(`${label("Route Definitions")} ${ctx.routeDefinitions.length}`);
			process.stdout.write(successBox([ctx.runtimeSettings.clientUrl ? colorize("whiteBright", `Report: ${ctx.runtimeSettings.clientUrl}`) : ""].join("\n"), title.join("\n")));
			if (existsSync(join(ctx.runtimeSettings.generatedClientPath, "reports", "lighthouse.json")) && ctx.resolvedConfig.cache) logger.info(`Restoring reports from cache. ${colorize("gray", "You can disable this behavior by passing --no-cache.")}`);
		}
		worker.queueRoutes(ctx.routes);
		return ctx;
	};
	if (ctx.resolvedConfig.site) ctx.setSiteUrl(resolvedConfig.site);
	return ctx;
}

//#endregion
//#region src/util.ts
const ReportArtifacts = {
	html: "payload.html",
	reportHtml: "lighthouse.html",
	screenshot: "screenshot.jpeg",
	fullScreenScreenshot: "full-screenshot.jpeg",
	screenshotThumbnailsDir: "__screenshot-thumbnails__",
	reportJson: "lighthouse.json"
};
/**
* Removes leading and trailing slashes from a string.
*
* @param s
*/
const trimSlashes = (s) => withoutLeadingSlash(withoutTrailingSlash(s));
/**
* Ensures slashes on both sides of a string
*
* @param s
*/
const withSlashes = (s) => withLeadingSlash(withTrailingSlash(s)) || "/";
/**
* Sanitises the provided URL for use as a file system path.
*
* @param url
* @return A sanitized URL, will retain the path hierarchy in the folder structure.
*/
function sanitiseUrlForFilePath(url) {
	url = trimSlashes(url);
	if (url.endsWith(".html")) url = url.replace(/\.html$/, "");
	return url.split("/").map((part) => sanitize(slugify(part))).join("/");
}
/**
* Turns a web path to a 6-char hash which can be used for easy identification.
*
* @param path
*/
function hashPathName(path$1) {
	return createHash("md5").update(sanitiseUrlForFilePath(path$1)).digest("hex").substring(0, 6);
}
/**
* Ensures a provided host is consistent, ensuring a protocol is provided.
*
* @param host
*/
function normaliseHost(host) {
	if (!host.startsWith("http")) host = `http${host.startsWith("localhost") ? "" : "s"}://${host}`;
	host = host.includes(".") ? host : withTrailingSlash(host);
	return new URL(host);
}
/**
* A task report is a wrapper for the route, the report file paths and task status.
*
* @param route
*/
function createTaskReportFromRoute(route) {
	const { runtimeSettings, resolvedConfig } = useUnlighthouse();
	const reportId = hashPathName(route.path);
	const reportPath = join(runtimeSettings.generatedClientPath, "reports", sanitiseUrlForFilePath(route.path));
	ensureDirSync(reportPath);
	return {
		tasks: {
			runLighthouseTask: "waiting",
			inspectHtmlTask: "waiting"
		},
		route,
		reportId,
		artifactPath: reportPath,
		artifactUrl: joinURL(resolvedConfig.routerPrefix, "reports", sanitiseUrlForFilePath(route.path))
	};
}
function base64ToBuffer(dataURI) {
	return Buffer.from(dataURI.split(",")[1], "base64");
}
function formatBytes(bytes, decimals = 2) {
	if (bytes === 0) return "0 Bytes";
	const k = 1024;
	const dm = decimals < 0 ? 0 : decimals;
	const sizes = [
		"Bytes",
		"KB",
		"MB",
		"GB",
		"TB",
		"PB",
		"EB",
		"ZB",
		"YB"
	];
	const i = Math.floor(Math.log(bytes) / Math.log(k));
	return `${Number.parseFloat((bytes / k ** i).toFixed(dm))} ${sizes[i]}`;
}
const _sharedContext = {};
function sharedContext() {
	return useUnlighthouse() || _sharedContext;
}
async function createAxiosInstance(resolvedConfig) {
	dns.setServers(["8.8.8.8", "1.1.1.1"]);
	const resolver = new dns.Resolver();
	resolver.setServers(["8.8.8.8", "1.1.1.1"]);
	const axiosOptions = {};
	if (resolvedConfig.auth) axiosOptions.auth = resolvedConfig.auth;
	axiosOptions.headers = axiosOptions.headers || {};
	if (resolvedConfig.cookies) axiosOptions.headers.Cookie = resolvedConfig.cookies.map((cookie) => `${cookie.name}=${cookie.value}`).join("; ");
	const userAgent = resolvedConfig.userAgent || resolvedConfig.lighthouseOptions.emulatedUserAgent || "Unlighthouse";
	axiosOptions.headers = {
		"User-Agent": userAgent,
		...resolvedConfig.extraHeaders || {},
		...axiosOptions.headers
	};
	if (resolvedConfig.defaultQueryParams) axiosOptions.params = {
		...resolvedConfig.defaultQueryParams,
		...axiosOptions.params
	};
	axiosOptions.httpsAgent = new https.Agent({
		rejectUnauthorized: false,
		keepAlive: true,
		timeout: 3e4
	});
	axiosOptions.httpAgent = new http.Agent({
		keepAlive: true,
		timeout: 3e4
	});
	axiosOptions.proxy = false;
	axiosOptions.timeout = 3e4;
	axiosOptions.withCredentials = true;
	const unlighthouse = sharedContext();
	unlighthouse._axios = axios.create(axiosOptions);
	return unlighthouse._axios;
}
async function fetchUrlRaw(url, resolvedConfig) {
	const logger = useLogger();
	const unlighthouse = sharedContext();
	const instance = unlighthouse._axios || await createAxiosInstance(resolvedConfig);
	const maxRetries = 3;
	let attempt = 0;
	while (attempt < maxRetries) try {
		const response = await instance.get(url, { timeout: 3e4 });
		let responseUrl = response.request.res.responseUrl;
		if (responseUrl && resolvedConfig.auth) responseUrl = responseUrl.replace(/(?<=https?:\/\/)(.+?@)/g, "");
		const redirected = responseUrl && responseUrl !== url;
		const redirectUrl = responseUrl;
		if (response.status < 200 || response.status >= 300 && !redirected) return {
			valid: false,
			redirected,
			response,
			redirectUrl
		};
		return {
			valid: true,
			redirected,
			response,
			redirectUrl
		};
	} catch (e) {
		if (e.errors) logger.error("Axios error:", e.errors);
		logger.error("Axios error message:", e.message);
		logger.error("Axios error code:", e.code);
		if (e.response) {
			logger.error("Axios error response data:", e.response.data);
			logger.error("Axios error response status:", e.response.status);
			logger.error("Axios error response headers:", e.response.headers);
		}
		if (e.code === "ETIMEDOUT" || e.code === "ENETUNREACH") {
			attempt++;
			logger.info(`Retrying request... (${attempt}/${maxRetries})`);
			continue;
		}
		return {
			error: e,
			valid: false
		};
	}
	return {
		error: new Error("Max retries reached"),
		valid: false
	};
}

//#endregion
export { ReportArtifacts, createUnlighthouse, defineConfig, fetchUrlRaw, generateClient, normaliseHost, useLogger, useUnlighthouse };